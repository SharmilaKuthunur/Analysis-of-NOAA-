{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of NOAA's Significant Earthquakes Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire project code is present in Sharmila_Kuthunur Analysis of NOAA Significant Earthquakes Dataset Jupyter notebook. The folder contains three sub-folders that represent three major stages in this project. \n",
    "\n",
    "\n",
    "    1. Preprocessing: Contains the processes executed to clean and filter the data. \n",
    "    2. Univariate Analysis: Contains analysis of numerical and categorical variables. \n",
    "    3. Bivariate Analysis: Contains analysis of combination of two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: \n",
    "\n",
    "The input data is a csv file downloaded from NOAA. [The dataset can be found over here to download](https://www.ngdc.noaa.gov/nndc/struts/results?bt_0=&st_0=&type_17=EXACT&query_17=None+Selected&op_12=eq&v_12=&type_12=Or&query_14=None+Selected&type_3=Like&query_3=&st_1=&bt_2=&st_2=&bt_1=&bt_4=&st_4=&bt_5=&st_5=&bt_6=&st_6=&bt_7=&st_7=&bt_8=&st_8=&bt_9=&st_9=&bt_10=&st_10=&type_11=Exact&query_11=&type_16=Exact&query_16=&bt_18=&st_18=&ge_19=&le_19=&type_20=Like&query_20=&display_look=1&t=101650&s=1&submit_all=Search+Database), and is also attached with the submission material. This dataset is taken as an input during preprocessing. After the data is preprocessed, the new dataset is downloaded as a CSV file for further analysis. This preprocessed dataset can be downloaded onto the local system by running the code in Preprocessing notebook, and is also attached with the submission material. \n",
    "\n",
    "While running the code, the location for the input data can be replaced by the address of the file on the local system. The following code needs to be changed: \n",
    "\n",
    "preprocessing_dataset = pd.read_csv(\"C:\\\\Users\\\\Sharmila\\\\Documents\\\\Earthquake Project\\\\Earthquake dataset.csv\")\n",
    "\n",
    "## Univariate and Bivariate Analysis: \n",
    "\n",
    "The input data are preprocessed csv files from Step 1. The modules for other graphs are maps are imported in the notebook itself and can be run on all local systems. The output is displayed right below the code itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the coding for this project has been done in Python 3.7.4.\n",
    "\n",
    "    Jupyter Notebook: Coding and explanation of written code. \n",
    "    Plotly: Execution of line graphs, scatter plots, and world map. \n",
    "    Spyder and Matplotlib: One graph titled 'Mean, Median, Mode of Magnitude' to display Magnitude column of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Name: Sharmila Kuthunur Gopala Krishna Rao\n",
    "    NUID: 001373718"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
